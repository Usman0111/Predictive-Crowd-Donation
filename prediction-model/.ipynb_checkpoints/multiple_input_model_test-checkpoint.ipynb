{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_days = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataset(csv_file_path):\n",
    "  file_data = pd.read_csv(csv_file_path)\n",
    "  file_data = file_data.drop('date', axis=1)\n",
    "  file_data = file_data.drop(0, axis=0)\n",
    "  print(\"File data DataFrame:\", file_data.shape)\n",
    "  print(file_data.head())\n",
    "  file_data = file_data.values\n",
    "  \n",
    "  normalizing_scaler = preprocessing.MinMaxScaler()\n",
    "  normalized_data = normalizing_scaler.fit_transform(file_data)\n",
    "  print()\n",
    "  print(\"Normalized data\")\n",
    "  print(normalized_data[0:5,:])\n",
    "  \n",
    "  # Data is in order of: Open stock value, high value, low, close, and volume - ohlcv\n",
    "  # Creates array of 5x50-value array windows, each one will be a training input into model\n",
    "  ohlcv_histories_normalised = np.array([normalized_data[i : i + history_days].copy() for i in range(len(normalized_data) - history_days)])\n",
    "  print()\n",
    "  print(\"Normalized inputs\", ohlcv_histories_normalised.shape)\n",
    "  #print(ohlcv_histories_normalised[0:2,0:5])\n",
    "  \n",
    "  # Get scaled stock open price values, which model is predicting\n",
    "  next_day_open_values_normalised = np.array([normalized_data[:,0][i + history_days].copy() for i in range(len(normalized_data) - history_days)])\n",
    "  next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)\n",
    "  #print()\n",
    "  print(\"Next day open values scaled:\", next_day_open_values_normalised.shape)\n",
    "  \n",
    "  # Get unscaled stock open price from original file data\n",
    "  next_day_open_values = np.array([file_data[:,0][i + history_days].copy() for i in range(len(file_data) - history_days)])\n",
    "  next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "  print(\"Next day open values unscaled:\", next_day_open_values.shape)\n",
    "\n",
    "  y_normaliser = preprocessing.MinMaxScaler()\n",
    "  y_normaliser.fit(next_day_open_values)\n",
    "\n",
    "  # Moving average technical indicator of stock price input\n",
    "  moving_averages = []\n",
    "  for his in ohlcv_histories_normalised:\n",
    "    sma = np.mean(his[:,3]) # Using closing price of the stocks for the moving average, not open price\n",
    "    moving_averages.append(np.array([sma]))\n",
    "\n",
    "  moving_averages = np.array(moving_averages) # Convert to numpy array\n",
    "  moving_averages_scaler = preprocessing.MinMaxScaler() # Scale with min-max scaler\n",
    "  moving_averages_normalised = moving_averages_scaler.fit_transform(moving_averages)\n",
    "\n",
    "  assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0] == moving_averages_normalised.shape[0]\n",
    "  return ohlcv_histories_normalised, moving_averages_normalised, next_day_open_values_normalised, next_day_open_values, y_normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_csv_to_dataset(test_set_name):\n",
    "  import os\n",
    "  ohlcv_histories = 0\n",
    "  moving_averages = 0\n",
    "  next_day_open_values = 0\n",
    "  # For each company stock dataset in directory, add data to training dataset\n",
    "  for csv_file_path in list(filter(lambda x: x.endswith('daily.csv'), os.listdir('./'))):\n",
    "    if not csv_file_path == test_set_name:\n",
    "      print(csv_file_path)\n",
    "      if type(ohlcv_histories) == int:\n",
    "        ohlcv_histories, moving_averages, next_day_open_values, _, _ = csv_to_dataset(csv_file_path)\n",
    "      else:\n",
    "        a, b, c, _, _ = csv_to_dataset(csv_file_path)\n",
    "        ohlcv_histories = np.concatenate((ohlcv_histories, a), 0)\n",
    "        moving_averages = np.concatenate((moving_averages, b), 0)\n",
    "        next_day_open_values = np.concatenate((next_day_open_values, c), 0)\n",
    "\n",
    "  ohlcv_train = ohlcv_histories\n",
    "  mov_avg_train = moving_averages\n",
    "  open_prices_train = next_day_open_values\n",
    "\n",
    "  ohlcv_test, mov_avg_test, open_prices_test, unscaled_open_prices_test, y_normaliser = csv_to_dataset(test_set_name)\n",
    "\n",
    "  return ohlcv_train, mov_avg_train, open_prices_train, ohlcv_test, mov_avg_test, open_prices_test, unscaled_open_prices_test, y_normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset of stock prices\n",
    "ohlcv_histories, moving_averages, next_day_open_values, unscaled_open_prices, y_normaliser = csv_to_dataset('MSFT_daily.csv')\n",
    "\n",
    "# Split into test and training sets\n",
    "train_split = 0.8\n",
    "n = int(ohlcv_histories.shape[0] * train_split)\n",
    "\n",
    "ohlcv_train = ohlcv_histories[:n]\n",
    "mov_avg_train = moving_averages[:n]\n",
    "open_prices_train = next_day_open_values[:n]\n",
    "\n",
    "ohlcv_test = ohlcv_histories[n:]\n",
    "mov_avg_test = moving_averages[n:]\n",
    "open_prices_test = next_day_open_values[n:]\n",
    "\n",
    "unscaled_open_prices_test = unscaled_open_prices[n:]\n",
    "\n",
    "\n",
    "\n",
    "# Multiple csv dataset function returns training and testing splits already, commented out above\n",
    "# Training set is now Microsoft, Netflix, and Facebook stock prices. Google stock prices is the test set\n",
    "#ohlcv_train, mov_avg_train, open_prices_train, ohlcv_test, mov_avg_test, open_prices_test, unscaled_open_prices_test, y_normaliser = multiple_csv_to_dataset('GOOGL_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model v2 - more complex layers, 2 inputs\n",
    "# Two sets of input into model - previous stock prices over time and the techincal indicator (moving average)\n",
    "lstm_input = Input(shape=(history_days, 5), name='lstm_input')\n",
    "dense_input = Input(shape=(mov_avg_train.shape[1],), name='tech_input')\n",
    " \n",
    "# First branch of model has layers for first input, stock prices from data\n",
    "x = LSTM(50, name='lstm_0')(lstm_input)\n",
    "x = Dropout(0.2, name='lstm_dropout_0')(x)\n",
    "lstm_branch = Model(inputs=lstm_input, outputs=x)\n",
    " \n",
    "# Second branch - Moving Average technical indicator input\n",
    "y = Dense(20, name='tech_dense_0')(dense_input)\n",
    "y = Activation(\"relu\", name='tech_relu_0')(y)\n",
    "y = Dropout(0.2, name='tech_dropout_0')(y)\n",
    "moving_averages_branch = Model(inputs=dense_input, outputs=y)\n",
    " \n",
    "# Combine two branches\n",
    "combined_branches = concatenate([lstm_branch.output, moving_averages_branch.output], name='concatenate')\n",
    "z = Dense(64, activation=\"sigmoid\", name='dense_pooling')(combined_branches)\n",
    "z = Dense(1, activation=\"linear\", name='dense_out')(z)\n",
    " \n",
    "# Model takes inputs from both branches, outputs a single value\n",
    "model = Model(inputs=[lstm_branch.input, moving_averages_branch.input], outputs=z)\n",
    "adam = optimizers.Adam(lr=0.0005)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[ohlcv_train, mov_avg_train], y=open_prices_train, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate([ohlcv_test, mov_avg_test], open_prices_test)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "# Open prices prediction\n",
    "open_prices_test_predicted = model.predict([ohlcv_test, mov_avg_test])\n",
    "open_prices_test_predicted = y_normaliser.inverse_transform(open_prices_test_predicted)\n",
    "\n",
    "# Entire training dataset prediction\n",
    "open_prices_predicted = model.predict([ohlcv_train, mov_avg_train])\n",
    "open_prices_predicted = y_normaliser.inverse_transform(open_prices_predicted)\n",
    "\n",
    "assert unscaled_open_prices_test.shape == open_prices_test_predicted.shape\n",
    "real_mse = np.mean(np.square(unscaled_open_prices_test - open_prices_test_predicted))\n",
    "scaled_mse = real_mse / (np.max(unscaled_open_prices_test) - np.min(unscaled_open_prices_test)) * 100\n",
    "print(scaled_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "start = 0\n",
    "end = -1\n",
    "real = plt.plot(unscaled_open_prices_test[start:end], label='real')\n",
    "pred = plt.plot(open_prices_test_predicted[start:end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'multiple_input_one_dataset_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "for ohlcv, ind in zip(ohlcv_test[start: end], mov_avg_test[start: end]):\n",
    "    normalised_price_today = ohlcv[-1][0]\n",
    "    normalised_price_today = np.array([[normalised_price_today]])\n",
    "    price_today = y_normaliser.inverse_transform(normalised_price_today)\n",
    "    predicted_price_tomorrow = np.squeeze(y_normaliser.inverse_transform(model.predict([[ohlcv], [ind]])))\n",
    "    if (x < 10):\n",
    "        print(predicted)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
